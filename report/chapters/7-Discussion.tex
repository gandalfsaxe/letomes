% !TEX root =../thesis-letomes.tex

\chapter{Discussion}

\todo{honestly, the problem is too low-dimensional for ES i think. The policy is too simple, so the RL-ES comparison is not that meaningful}

\section{Brute Force vs. ES}
In this section, we will examine the usefulness of using the ES algorithm over the brute force alternative. Do we get anything out of estimating a gradient? Do our resultsâ€™ quality scale with a more complex model?

The ES method is in the general case a more intelligent of searching for these things. However, its not a magical panacea that just spits out fabulous results from a naive application. The brute force method took advantage of a lot of human intuition in terms of where to search. We gave it a limited fan of possibilities in a region that we knew to be reasonable. The ES algorithm definitely gave the best results when we imposed equivalent limitations on it.

\section{Delta-v Travel Time Trade-off}
Delta-v Travel Time Trade-off. Plot this, if we can get enough different successful trajectories. What does that plot look like?

\section{Performance Optimization}
Computing performance ended up representing a large portion of our efforts in this project, perhaps even more that we anticipated, and the tradeoff between code readability and performance was drawn in stark relief. We used several tools to make things easier: Initially, we wanted to get the parallelism 'for free' by using PaGMO to handle our multi-threading and use Numba to compile our python scripts. Seemed like a good idea; that's what the respective tools are made for. However, while Numba definitely gave fantastic performance increases over normal python, it was not enough. And while PaGMO worked fine (after some work getting it running at all), it only parallelized to CPUs, and had an absolutely hilarious startup overhead that made rapid prototyping (one of the main draws of python) tedious to say the least. 

In the end, we had to apply the adage of \textit{"if you want something done right, do it yourself"}, and implement these things by hand, with a C implementation of the integrator, and a CUDA interface for parallelization. This of course also meant redesigning the otherwise simple ES algorithm to fit the much less sophisticated data types that graphics cards work with. It was easily worth the effort. This new iteration of the program completes four orders of magnitude more fitness evaluations in roughly the same time, compared to its predecessor. It makes it reasonable to get results with \textit{some} confidence that the problem space is significantly explored. 

More performance would be nice, and definitely achievable, but we have hit a point of diminishing returns on further effort in this regard. The obvious possible improvements would be to reduce the number of variables that we save in the core integrator loop: We use 96 registers per parallel evaluation, which means that the card is memory capped at 25\% capacity. We could realistically expect a doubling in performance if we refactored the C integrator with this in mind. Again, we didn't bother with this, since the current speed is good \textit{enough}.

\section{Self-evaluation}
Was our time well spent? Did we gain anything from our "reinventing the wheel", re-implementing the lunar simulator? Should we have focused on running on the old code without delving into it?

If we could go back in time to the start of the project, and counsel our past selves, we would tell ourselves to not underestimate the complexity of scaling the moon-problem to 3D. We should break that monolithic problem into smaller problems instead, something that would have let us attack three separate 2D problems with some handover logic instead. Especially, we should have admitted to ourselves earlier that there is not much interesting optimization to do on the long deep space section of the trajectory, and that any LETO magic will happen very close to Mars. This is a case of difference in scale becoming a difference in kind between having the moon and mars as your target. The distance is so great between earth and mars that LETOs of the earth-moon kind--where we go back and forth between the two bodies repeatedly--make the mission utterly uninteresting. In the the moon mission case, this turns a travel time of days to one of months. Fine, if the mission is unmanned. In a Mars mission, it takes a travel time of months and turns it into decades or centuries. At that scale, whatever technology you are sending up will be antiquated by the time it arrives. We simply do not see a reasonable use-case for a supply mission that takes a hundred years to arrive. The literature also supports this indirectly; we have not been able to find any literature that tries to optimize on the fundamental shape of the hohmann transfer. All the interesting optimizations happen within a couple million kilometers of Mars.