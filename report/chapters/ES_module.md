# The ES module

The ES module conducts black-box optimization on a decision vector that describes the initial parameters for a launch. Every time the algorithm wants to find the fitness of a given point in our parameter space, it calls the orbsim module with those parameters, using the returned value as the function to minimize. The algorithm is parallelized through the use of PaGMO, which runs the ES algorithm on multiple cores independently, with many separate starting conditions. 

## DERP

The module defines a pygmo *problem* class, which gives the bounds and fitness function for our optimization space. The fitness function takes the decision vector $\psi$ as argument, calls on orbsim to run a simulation with the contained parameters, and returns the result of that simulation: The $\Delta v$ value, or if the rocket did not hit the target, how close it came at the minimum. The fitness is a single scalar, so the fact that that scalar can mean two different things (a change in velocity or a distance) gives some problems for estimating gradients in our space. We mitigate this by penalizing an unsuccessful mission heavily, by adding an upward bias and weight, as well as squaring the result, to amplify the effect of small differences in minimum distance.

We then define the ES algorithm within the pygmo framework, which defines an *evolve* function, which executes a single run of the algorithm. This function takes a *population* $\Psi$, a collection of decision vectors, and for each vector at step *t* ($\psi_{i,t}$) creates several jittered copies of those vectors, akin to creating a gaussian point cloud in the 3-dimensional problem space that the vectors span. Each of these points is then tested (the fitness function is run) and the average of those jittered points, weighted according to fitness score, is deemed as the location for the next point $\psi_{i,t+1}$. The algorithm then runs until it has converged upon a local minimum, or until some maximum number of steps has been reached.

Next, we create an *archipelago*, another pygmo concept. It is, as the name suggests, a collection of *islands* which each run the algorithm on their own separate populations. Each island runs in parallel. This convenient metaphor and easy implementation is the main draw of pygmo for us. 